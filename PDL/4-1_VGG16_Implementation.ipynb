{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"4-1_VGG16_Implementation.ipynb","provenance":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.5"}},"cells":[{"cell_type":"markdown","metadata":{"id":"jQAccyZaeyS9"},"source":["# 実習4-1 \n","# VGG16をkerasで実装してみる\n","### VGG16は2014年のILSVRCでGoogleのGoogLeNetに次ぐ2位の成績を出したアルゴリズム(1位はgoogleのGoogLeNet)。畳み込み13層とフル結合3層の計16層から成る畳み込みニューラルネットワーク。\n","### ここでは、ImageNetで使っている重みそのままを使用。\n","### Keras Docsより詳細(https://keras.io/ja/applications/)"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VjerxyXheyTA","executionInfo":{"status":"ok","timestamp":1613192102702,"user_tz":-540,"elapsed":7934,"user":{"displayName":"Kosuke Harada","photoUrl":"","userId":"03431199727064994008"}},"outputId":"7560e9b7-fc53-4884-874d-d88df6e8669d"},"source":["from keras.applications.vgg16 import VGG16\n","model = VGG16(include_top=True, weights='imagenet', input_tensor=None, input_shape=None)\n","#from keras.applications.inception_v3 import InceptionV3\n","#model = InceptionV3(include_top=True, weights='imagenet', input_tensor=None, input_shape=None)"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels.h5\n","553467904/553467096 [==============================] - 3s 0us/step\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OS-XKi6CeyTG","executionInfo":{"status":"ok","timestamp":1613192103073,"user_tz":-540,"elapsed":8294,"user":{"displayName":"Kosuke Harada","photoUrl":"","userId":"03431199727064994008"}},"outputId":"69b14ffa-879b-4336-a4a3-f956e741001f"},"source":["model.summary()\n","# 最後の(None, 1000)は1000クラス分類であることを示す。\n","# Noneは入力サンプル数（入力バッチ数）が決まってないことを意味する。"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Model: \"vgg16\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input_1 (InputLayer)         [(None, 224, 224, 3)]     0         \n","_________________________________________________________________\n","block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n","_________________________________________________________________\n","block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n","_________________________________________________________________\n","block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n","_________________________________________________________________\n","block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n","_________________________________________________________________\n","block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n","_________________________________________________________________\n","block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n","_________________________________________________________________\n","block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n","_________________________________________________________________\n","block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n","_________________________________________________________________\n","block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n","_________________________________________________________________\n","block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n","_________________________________________________________________\n","block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n","_________________________________________________________________\n","block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n","_________________________________________________________________\n","block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n","_________________________________________________________________\n","block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n","_________________________________________________________________\n","block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n","_________________________________________________________________\n","block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n","_________________________________________________________________\n","block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n","_________________________________________________________________\n","block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n","_________________________________________________________________\n","flatten (Flatten)            (None, 25088)             0         \n","_________________________________________________________________\n","fc1 (Dense)                  (None, 4096)              102764544 \n","_________________________________________________________________\n","fc2 (Dense)                  (None, 4096)              16781312  \n","_________________________________________________________________\n","predictions (Dense)          (None, 1000)              4097000   \n","=================================================================\n","Total params: 138,357,544\n","Trainable params: 138,357,544\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_tl3G4kFeyTJ","executionInfo":{"status":"ok","timestamp":1613192167801,"user_tz":-540,"elapsed":4102,"user":{"displayName":"Kosuke Harada","photoUrl":"","userId":"03431199727064994008"}},"outputId":"f53f33bc-5160-47f9-a415-4a1f86319db2"},"source":["#自分で画像を入力し、学習済みのVGG16にクラスの予測をさせる\n","from keras.applications.vgg16 import VGG16, preprocess_input, decode_predictions\n","from keras.preprocessing import image\n","import numpy as np\n","\n","# 学習済みのVGG16をロード\n","# 構造とともに学習済みの重みも読み込まれる\n","model = VGG16(weights='imagenet')\n","\n","# 引数で指定した画像ファイルを読み込む\n","# サイズはVGG16のデフォルトである224x224にリサイズされる\n","filename = \"cat.jpg\"\n","img = image.load_img(filename, target_size=(224, 224))\n","\n","# 読み込んだPIL形式の画像をarrayに変換\n","x = image.img_to_array(img)\n","print(x.shape)\n","\n","# 3次元テンソル（rows, cols, channels) を\n","# 4次元テンソル (samples, rows, cols, channels) に変換\n","# 入力画像は1枚なのでsamples=1でよい\n","x = np.expand_dims(x, axis=0)\n","print(x.shape)\n","\n","# Top-5のクラスを予測する\n","# predict()の戻り値はNNの出力であり1000クラスの確率値\n","# VGG16の1000クラスはdecode_predictions()で文字列に変換される\n","preds = model.predict(preprocess_input(x))\n","results = decode_predictions(preds, top=5)[0]\n","\n","for result in results:\n","    print(result)\n","    \n","# 結果として(WordNet ID, クラス名, 確率)が表示される"],"execution_count":4,"outputs":[{"output_type":"stream","text":["(224, 224, 3)\n","(1, 224, 224, 3)\n","Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/imagenet_class_index.json\n","40960/35363 [==================================] - 0s 0us/step\n","('n02124075', 'Egyptian_cat', 0.17095202)\n","('n02123597', 'Siamese_cat', 0.13552622)\n","('n02123045', 'tabby', 0.070369914)\n","('n02342885', 'hamster', 0.050093345)\n","('n02883205', 'bow_tie', 0.049812306)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"collapsed":true,"id":"D3hzE2zUeyTL"},"source":["### 課題4-1-1\n","#### 適当な画像を用意してVGG16に入力し、判別させてみましょう。"]},{"cell_type":"code","metadata":{"id":"6YPB2-OEeyTM"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"72jtj-MPeyTN"},"source":[""],"execution_count":null,"outputs":[]}]}