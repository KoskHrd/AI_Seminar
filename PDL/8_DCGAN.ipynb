{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.5"},"colab":{"name":"8_DCGAN.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"PcdheQB8TfAL"},"source":["# 実習8\n","\n","#### GANを体験する\n","\n","以下のHPを参考にして下さい。\n","https://elix-tech.github.io/ja/2017/02/06/gan.html\n","https://qiita.com/God_KonaBanana/items/293d49e3c34601a1810b"]},{"cell_type":"code","metadata":{"id":"iwCs6MoSTfAO","executionInfo":{"status":"ok","timestamp":1613807392557,"user_tz":-540,"elapsed":2090,"user":{"displayName":"Kosuke Harada","photoUrl":"","userId":"03431199727064994008"}}},"source":["# generatorを作成\n","\n","from keras.models import Sequential\n","from keras.layers import Dense, Activation, Reshape\n","from keras.layers.normalization import BatchNormalization\n","from keras.layers.convolutional import UpSampling2D, Convolution2D\n","\n","def generator_model():\n","    model = Sequential()\n","    model.add(Dense(input_dim=100, units=1024)) #100次元のノイズベクトルがinput\n","    model.add(BatchNormalization())\n","    model.add(Activation('relu'))\n","    model.add(Dense(128*7*7))\n","    model.add(BatchNormalization())\n","    model.add(Activation('relu'))\n","    model.add(Reshape((7, 7, 128), input_shape=(128*7*7,))) #サイズ7x7　128chの画像\n","    model.add(UpSampling2D((2, 2)))\n","    model.add(Convolution2D(64, (5,5), padding='same'))\n","    model.add(BatchNormalization())\n","    model.add(Activation('relu'))\n","    model.add(UpSampling2D((2, 2)))\n","    model.add(Convolution2D(1, (5,5), padding='same'))\n","    model.add(Activation('tanh'))\n","    return model"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"id":"wloekr8sTfAU","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1613807398534,"user_tz":-540,"elapsed":8060,"user":{"displayName":"Kosuke Harada","photoUrl":"","userId":"03431199727064994008"}},"outputId":"55b6abe0-e3fa-4af8-f157-87ac87153947"},"source":["# generator_modelが(28, 28, 1)の画像を出力していることを確認\n","model = generator_model()\n","model.summary()"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Model: \"sequential\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense (Dense)                (None, 1024)              103424    \n","_________________________________________________________________\n","batch_normalization (BatchNo (None, 1024)              4096      \n","_________________________________________________________________\n","activation (Activation)      (None, 1024)              0         \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 6272)              6428800   \n","_________________________________________________________________\n","batch_normalization_1 (Batch (None, 6272)              25088     \n","_________________________________________________________________\n","activation_1 (Activation)    (None, 6272)              0         \n","_________________________________________________________________\n","reshape (Reshape)            (None, 7, 7, 128)         0         \n","_________________________________________________________________\n","up_sampling2d (UpSampling2D) (None, 14, 14, 128)       0         \n","_________________________________________________________________\n","conv2d (Conv2D)              (None, 14, 14, 64)        204864    \n","_________________________________________________________________\n","batch_normalization_2 (Batch (None, 14, 14, 64)        256       \n","_________________________________________________________________\n","activation_2 (Activation)    (None, 14, 14, 64)        0         \n","_________________________________________________________________\n","up_sampling2d_1 (UpSampling2 (None, 28, 28, 64)        0         \n","_________________________________________________________________\n","conv2d_1 (Conv2D)            (None, 28, 28, 1)         1601      \n","_________________________________________________________________\n","activation_3 (Activation)    (None, 28, 28, 1)         0         \n","=================================================================\n","Total params: 6,768,129\n","Trainable params: 6,753,409\n","Non-trainable params: 14,720\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"sWkQm40DTfAX","executionInfo":{"status":"ok","timestamp":1613807398535,"user_tz":-540,"elapsed":8059,"user":{"displayName":"Kosuke Harada","photoUrl":"","userId":"03431199727064994008"}}},"source":["# discriminatorを作成\n","\n","from keras.layers.advanced_activations import LeakyReLU\n","from keras.layers import Flatten, Dropout\n","\n","def discriminator_model():\n","    model = Sequential()\n","    model.add(Convolution2D(64, (5, 5),\n","                            strides=(2, 2),\n","                            padding='same',\n","                            input_shape=(28, 28, 1)))\n","    model.add(LeakyReLU(0.2))\n","    model.add(Convolution2D(128, (5, 5), strides=(2, 2)))\n","    model.add(LeakyReLU(0.2))\n","    model.add(Flatten())\n","    model.add(Dense(256))\n","    model.add(LeakyReLU(0.2))\n","    model.add(Dropout(0.5))\n","    model.add(Dense(1))\n","    model.add(Activation('sigmoid'))\n","    return model"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"yBXDUzqmTfAa","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1613807398536,"user_tz":-540,"elapsed":8057,"user":{"displayName":"Kosuke Harada","photoUrl":"","userId":"03431199727064994008"}},"outputId":"5b335196-9610-4df4-985c-aeb24a35e532"},"source":["# discriminator_modelの中身、最後はsigmoidで確率を出力\n","model = discriminator_model()\n","model.summary()"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Model: \"sequential_1\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","conv2d_2 (Conv2D)            (None, 14, 14, 64)        1664      \n","_________________________________________________________________\n","leaky_re_lu (LeakyReLU)      (None, 14, 14, 64)        0         \n","_________________________________________________________________\n","conv2d_3 (Conv2D)            (None, 5, 5, 128)         204928    \n","_________________________________________________________________\n","leaky_re_lu_1 (LeakyReLU)    (None, 5, 5, 128)         0         \n","_________________________________________________________________\n","flatten (Flatten)            (None, 3200)              0         \n","_________________________________________________________________\n","dense_2 (Dense)              (None, 256)               819456    \n","_________________________________________________________________\n","leaky_re_lu_2 (LeakyReLU)    (None, 256)               0         \n","_________________________________________________________________\n","dropout (Dropout)            (None, 256)               0         \n","_________________________________________________________________\n","dense_3 (Dense)              (None, 1)                 257       \n","_________________________________________________________________\n","activation_4 (Activation)    (None, 1)                 0         \n","=================================================================\n","Total params: 1,026,305\n","Trainable params: 1,026,305\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"4RNP3uatTfAc","colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1u6c51MVW2RNKRCMFRXt7cqIi__sgsroF"},"executionInfo":{"status":"ok","timestamp":1613809401030,"user_tz":-540,"elapsed":2010548,"user":{"displayName":"Kosuke Harada","photoUrl":"","userId":"03431199727064994008"}},"outputId":"98636849-d49b-49e2-dd70-3b1772f37b97"},"source":["# 学習部分\n","\n","import os\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from keras.datasets import mnist\n","from keras.optimizers import Adam\n","from PIL import Image\n","\n","BATCH_SIZE = 32\n","NUM_EPOCH = 20\n","GENERATED_IMAGE_PATH = 'generated_images/' # 生成画像の保存先\n","\n","#loadした画像は0-1でクリップするのではなく、-1から1でクリップするのがGANでは一般的なようです。\n","#そのため、/255.0ではなく、127.5を引いてから/127.5します。\n","(X_train, y_train), (_, _) = mnist.load_data()\n","X_train = (X_train.astype(np.float32) - 127.5)/127.5\n","X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], X_train.shape[2],1)\n","print(X_train.shape)\n","\n","# discriminator\n","discriminator = discriminator_model()\n","d_opt = Adam(lr=1e-5, beta_1=0.1)\n","discriminator.compile(loss='binary_crossentropy', optimizer=d_opt)\n","\n","# generator+discriminator （discriminator部分の重みは固定）\n","discriminator.trainable = False\n","generator = generator_model()\n","dcgan = Sequential([generator, discriminator])\n","g_opt = Adam(lr=2e-4, beta_1=0.5)\n","dcgan.compile(loss='binary_crossentropy', optimizer=g_opt)\n","\n","# 1 epochの中のminibach数を定義\n","num_batches = int(X_train.shape[0] / BATCH_SIZE) # num_batches= 1875\n","print('Number of batches:', num_batches)\n","for epoch in range(NUM_EPOCH):\n","\n","    # -1から1までの100次元の乱数をBATCH_SIZE(=32)個生成。これがGeneratorの入力になる。shape=(32,100)\n","    # データセットの方からも32枚の画像を抽出\n","    # generated_imagesがGeneratorによって生成された画像\n","    for index in range(num_batches):\n","        noise = np.array([np.random.uniform(-1, 1, 100) for _ in range(BATCH_SIZE)])\n","        image_batch = X_train[index*BATCH_SIZE:(index+1)*BATCH_SIZE]\n","        generated_images = generator.predict(noise, verbose=0)\n","\n","        # 500batch学習毎に生成画像を出力\n","        if index % 500 == 0:\n","\n","            # generate images and shape\n","            generated_images_plot = generated_images.astype('float32') * 127.5 + 127.5\n","            generated_images_plot = generated_images_plot.reshape((BATCH_SIZE, 28, 28))\n","\n","            plt.figure(figsize=(8, 4))\n","            plt.suptitle('epoch=%04d,index=%04d' % (epoch, index), fontsize=20)\n","            for i in range(BATCH_SIZE):\n","                plt.subplot(4, 8, i + 1)\n","                plt.imshow(generated_images_plot[i])\n","                plt.gray()\n","                # eliminate ticks\n","                plt.xticks([]), plt.yticks([])\n","\n","\n","            # save images\n","            if not os.path.exists(GENERATED_IMAGE_PATH):\n","                os.mkdir(GENERATED_IMAGE_PATH)\n","            filename = GENERATED_IMAGE_PATH + \"MNIST_%04d_%04d.png\" % (epoch,index)\n","            plt.savefig(filename)\n","                \n","        # discriminatorを更新\n","        X = np.concatenate((image_batch, generated_images))\n","        y = [1]*BATCH_SIZE + [0]*BATCH_SIZE #教師データ:1が32個連続し、0が32個連続したベクトル\n","        y = np.asarray(y).astype('float32').reshape((-1,1))\n","        d_loss = discriminator.train_on_batch(X, y) #.train_on_batchは1つのバッチで勾配を更新\n","\n","        # generatorを更新\n","        noise = np.array([np.random.uniform(-1, 1, 100) for _ in range(BATCH_SIZE)])\n","        y = [1]*BATCH_SIZE\n","        g_loss = dcgan.train_on_batch(noise, np.asarray(y).astype('float32').reshape((-1,1))) # モデルdcganの学習、この時descriminatorの重みは更新されない\n","        print(\"epoch: %d, batch: %d, g_loss: %f, d_loss: %f\" % (epoch, index, g_loss, d_loss))\n","\n","    generator.save_weights('generator.h5')\n","    discriminator.save_weights('discriminator.h5')\n"],"execution_count":5,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"code","metadata":{"id":"iQquFbczTfAd","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1613809401032,"user_tz":-540,"elapsed":2010547,"user":{"displayName":"Kosuke Harada","photoUrl":"","userId":"03431199727064994008"}},"outputId":"e4db5d6c-4499-4c67-d631-2445bb972827"},"source":["BATCH_SIZE = 32\n","y = [1]*BATCH_SIZE + [0]*BATCH_SIZE\n","y = np.asarray(y).astype('float32').reshape((-1,1))\n","y"],"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[1.],\n","       [1.],\n","       [1.],\n","       [1.],\n","       [1.],\n","       [1.],\n","       [1.],\n","       [1.],\n","       [1.],\n","       [1.],\n","       [1.],\n","       [1.],\n","       [1.],\n","       [1.],\n","       [1.],\n","       [1.],\n","       [1.],\n","       [1.],\n","       [1.],\n","       [1.],\n","       [1.],\n","       [1.],\n","       [1.],\n","       [1.],\n","       [1.],\n","       [1.],\n","       [1.],\n","       [1.],\n","       [1.],\n","       [1.],\n","       [1.],\n","       [1.],\n","       [0.],\n","       [0.],\n","       [0.],\n","       [0.],\n","       [0.],\n","       [0.],\n","       [0.],\n","       [0.],\n","       [0.],\n","       [0.],\n","       [0.],\n","       [0.],\n","       [0.],\n","       [0.],\n","       [0.],\n","       [0.],\n","       [0.],\n","       [0.],\n","       [0.],\n","       [0.],\n","       [0.],\n","       [0.],\n","       [0.],\n","       [0.],\n","       [0.],\n","       [0.],\n","       [0.],\n","       [0.],\n","       [0.],\n","       [0.],\n","       [0.],\n","       [0.]], dtype=float32)"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"code","metadata":{"id":"ppx_OOXvTfAf","executionInfo":{"status":"ok","timestamp":1613809401032,"user_tz":-540,"elapsed":2010545,"user":{"displayName":"Kosuke Harada","photoUrl":"","userId":"03431199727064994008"}}},"source":[""],"execution_count":6,"outputs":[]}]}